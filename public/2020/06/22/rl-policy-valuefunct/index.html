<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"xiaoxiang-ma.github.io","root":"/blog/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1. PoliciesFormally, a policy is a mapping from states to probabilities of selecting each possible action. If the agent is following policy $\pi$ at time $t$, then $\pi(a | s)$ is the probability that">
<meta property="og:type" content="article">
<meta property="og:title" content="Policies, Value functions, Optimality">
<meta property="og:url" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/index.html">
<meta property="og:site_name" content="(▀̿Ĺ̯▀̿ ̿)">
<meta property="og:description" content="1. PoliciesFormally, a policy is a mapping from states to probabilities of selecting each possible action. If the agent is following policy $\pi$ at time $t$, then $\pi(a | s)$ is the probability that">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/statevalue.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/v.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/actionvalue.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/q.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/bellman.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/tree.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/grid.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/computingV1.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/computingV2.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/optimalv.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/optimalq.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/optimal_graphical.png">
<meta property="og:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/optimalpolicy.png">
<meta property="article:published_time" content="2020-06-22T19:31:56.000Z">
<meta property="article:modified_time" content="2020-07-02T02:58:14.418Z">
<meta property="article:author" content="Xiaoxiang Ma">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="RL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/statevalue.png">

<link rel="canonical" href="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Policies, Value functions, Optimality | (▀̿Ĺ̯▀̿ ̿)</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">(▀̿Ĺ̯▀̿ ̿)</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Ma blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://xiaoxiang-ma.github.io/blog/2020/06/22/rl-policy-valuefunct/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Xiaoxiang Ma">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="(▀̿Ĺ̯▀̿ ̿)">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Policies, Value functions, Optimality
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-06-22 15:31:56" itemprop="dateCreated datePublished" datetime="2020-06-22T15:31:56-04:00">2020-06-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/Data-Science/" itemprop="url" rel="index"><span itemprop="name">Data Science</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="1-Policies"><a href="#1-Policies" class="headerlink" title="1. Policies"></a>1. Policies</h2><p>Formally, a policy is a mapping from states to probabilities of selecting each possible action. If the agent is following policy $\pi$ at time $t$, then $\pi(a | s)$ is the probability that $A_t=a$ if $S_t=s$.</p>
<p><strong>Deterministic</strong> policy: A policy that maps each state to a single action.</p>
<p><strong>Stochastic</strong> policy: A policy where multiple actions may be selected with non-zero probability. The probabilities are non-negative and sum to 1.</p>
<p><strong><em>Policies tell an agent how to behave in their environment.</em></strong></p>
<p><strong><em>Policy can depend only on the current state, and not other things like time or previous states.</em></strong></p>
<h2 id="2-Value-functions"><a href="#2-Value-functions" class="headerlink" title="2. Value functions"></a>2. Value functions</h2><p>Value functions estimate future returns under a specific policy.</p>
<h3 id="State-value-function"><a href="#State-value-function" class="headerlink" title="State-value function"></a><strong>State-value function</strong></h3><p>The expected return when starting in s and following policy $\pi$ thereafter.</p>
<img src="/blog/2020/06/22/rl-policy-valuefunct/statevalue.png" class="" title="(G: return)">
<img src="/blog/2020/06/22/rl-policy-valuefunct/v.png" class="">


<h3 id="Action-value-function"><a href="#Action-value-function" class="headerlink" title="Action-value function"></a><strong>Action-value function</strong></h3><p>The value of taking action a in state s and following policy $\pi$ thereafter.</p>
<img src="/blog/2020/06/22/rl-policy-valuefunct/actionvalue.png" class="">
<img src="/blog/2020/06/22/rl-policy-valuefunct/q.png" class="">

<p>Value functions allow an agent to query the quality of its current situation instead of waiting to observe the long-term outcome. </p>
<p>Benefits:</p>
<ul>
<li>The return is not immediately available.</li>
<li>The return may be random due to stochasticity in both the policy and environment dynamics. </li>
</ul>
<p>The value function summarizes all the possible futures by averaging over returns. Ultimately, we care most about <strong><em>learning a good policy</em></strong>. Value function enable us to judge the quality of different policies.</p>
<h3 id="Bellman-equation-for-v-pi"><a href="#Bellman-equation-for-v-pi" class="headerlink" title="Bellman equation for $v_\pi$"></a>Bellman equation for $v_\pi$</h3><p>Expresses a relationship between the <strong><em>value of a state</em></strong> and the <strong><em>values of its successor states.</em></strong></p>
<!-- It states that the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way.
(Refer to previous definitions of v) -->

<p>The Bellman equation for the state value function gives the value of the current state as a sum over the values of all the successor states, and immediate rewards. </p>
<img src="/blog/2020/06/22/rl-policy-valuefunct/bellman.png" class="" title="Bellman Equation">


<p>$\sum$ (Action $a$’s probability under current state $s$ $\times \sum$  (probability of next state <em>s’</em> given $a$ is taken under $s$) $\times$ (corresponding reward $r$ + discounted value of state <em>s’</em> ))</p>
<img src="/blog/2020/06/22/rl-policy-valuefunct/tree.png" class="" title="Explains 3.14 graphically">


<img src="/blog/2020/06/22/rl-policy-valuefunct/grid.png" class="" title="Example of finite MDP">


<h3 id="Using-Bellman-equation-and-computing-v"><a href="#Using-Bellman-equation-and-computing-v" class="headerlink" title="Using Bellman equation and computing $v$"></a>Using Bellman equation and computing $v$</h3><img src="/blog/2020/06/22/rl-policy-valuefunct/computingV1.png" class="" title="Simple case: only one future state for each action">
<img src="/blog/2020/06/22/rl-policy-valuefunct/computingV2.png" class="" title="Now solve linear equations">

<p><a href="https://github.com/LyWangPX/Reinforcement-Learning-2nd-Edition-by-Sutton-Exercise-Solutions" target="_blank" rel="noopener">Excercises Answers</a></p>
<h2 id="3-Optimality"><a href="#3-Optimality" class="headerlink" title="3. Optimality"></a>3. Optimality</h2><p>There is always at least one policy that is better than or equal to all other policies. This is an optimal policy. Although there may be more than one, we denote all the optimal policies by $\pi *$.</p>
<h3 id="Optimal-state-value-function-v"><a href="#Optimal-state-value-function-v" class="headerlink" title="Optimal state value function ($v_*$)"></a>Optimal state value function ($v_*$)</h3><img src="/blog/2020/06/22/rl-policy-valuefunct/optimalv.png" class="">


<h3 id="Optimal-action-value-function-q"><a href="#Optimal-action-value-function-q" class="headerlink" title="Optimal action value function ($q_*$)"></a>Optimal action value function ($q_*$)</h3><img src="/blog/2020/06/22/rl-policy-valuefunct/optimalq.png" class="">
<img src="/blog/2020/06/22/rl-policy-valuefunct/optimal_graphical.png" class="">

<h3 id="Optimal-policy"><a href="#Optimal-policy" class="headerlink" title="Optimal policy"></a>Optimal policy</h3><img src="/blog/2020/06/22/rl-policy-valuefunct/optimalpolicy.png" class="">


    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/%E7%AC%94%E8%AE%B0/" rel="tag"># 笔记</a>
              <a href="/blog/tags/RL/" rel="tag"># RL</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2020/06/18/rl-mdp/" rel="prev" title="Finite Markov Decision Processes & Rewards">
      <i class="fa fa-chevron-left"></i> Finite Markov Decision Processes & Rewards
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2020/07/01/neuralnet/" rel="next" title="Neural Networks & Deep Learning">
      Neural Networks & Deep Learning <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Policies"><span class="nav-text">1. Policies</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Value-functions"><span class="nav-text">2. Value functions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#State-value-function"><span class="nav-text">State-value function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Action-value-function"><span class="nav-text">Action-value function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bellman-equation-for-v-pi"><span class="nav-text">Bellman equation for $v_\pi$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-Bellman-equation-and-computing-v"><span class="nav-text">Using Bellman equation and computing $v$</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Optimality"><span class="nav-text">3. Optimality</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimal-state-value-function-v"><span class="nav-text">Optimal state value function ($v_*$)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimal-action-value-function-q"><span class="nav-text">Optimal action value function ($q_*$)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Optimal-policy"><span class="nav-text">Optimal policy</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Xiaoxiang Ma</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xiaoxiang-ma" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xiaoxiang-ma" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xm53@cornell.edu" title="Email → mailto:xm53@cornell.edu" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Email</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://medium.com/@xiaoxiangma" title="Medium → https:&#x2F;&#x2F;medium.com&#x2F;@xiaoxiangma" rel="noopener" target="_blank"><i class="fab fa-medium fa-fw"></i>Medium</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiaoxiang Ma</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
